{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import cv2\nimport numpy as np\nimport os\nfrom os.path import isfile, join\nimport matplotlib.pyplot as plt\npathIn= '/kaggle/input/eveerybody-dance-nowsubject-2/subject2/train/train_img/'\npathOut = 'videosourcesubject2.avi'\nfps = 20\nframe_array = []\nfiles = [f for f in os.listdir(pathIn) if isfile(join(pathIn, f))]\n#files.sort(key = lambda x: x[5:-4])\nfiles.sort()\nframe_array = []\n#files = [f for f in os.listdir(pathIn) if isfile(join(pathIn, f))]\n#files.sort(key = lambda x: x[5:-4])\nfor i in range(1000):\n    filename=pathIn + files[i]\n    if(i==50):\n        print(files[i])\n    img = cv2.imread(filename)\n    height, width, layers = img.shape\n    size = (width,height)\n    frame_array.append(img)\nout = cv2.VideoWriter(pathOut,cv2.VideoWriter_fourcc(*'DIVX'), fps, size)\nfor i in range(len(frame_array)):\n    out.write(frame_array[i])\nout.release()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport cv2\nfrom os import listdir\nfrom numpy import asarray\nfrom numpy import vstack\nfrom keras.preprocessing.image import img_to_array\nfrom keras.preprocessing.image import load_img\nfrom numpy import savez_compressed\nimport keras\nimport numpy as np\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nclass My_Custom_Generator(keras.utils.Sequence) :\n    def __init__(self, image_filenames_label,image_filenames_img, labels, batch_size) :\n        self.image_filenames = [image_filenames_label,image_filenames_img]\n        self.labels = labels\n        self.batch_size = batch_size\n    def __len__(self) :\n        return (np.ceil(len(self.image_filenames) / float(self.batch_size))).astype(np.int)\n  \n    def __getitem__(self, idx) :\n        batch_x = [self.image_filenames[0][idx * self.batch_size : (idx+1) * self.batch_size],self.image_filenames[1][idx * self.batch_size : (idx+1) * self.batch_size]]\n        batch_y = self.labels[idx * self.batch_size : (idx+1) * self.batch_size]\n       \n    \n        return (batch_x), np.array(batch_y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class My_Custom_Generator_gan(keras.utils.Sequence) :\n    def __init__(self, image_filenames_label, labels,images_filenames_img, batch_size) :\n        self.image_filenames = image_filenames_label\n        self.labels = [labels,images_filenames_img]\n        self.batch_size = batch_size\n    def __len__(self) :\n        return (np.ceil(len(self.image_filenames) / float(self.batch_size))).astype(np.int)\n  \n    def __getitem__(self, idx) :\n        batch_x = self.image_filenames[idx * self.batch_size : (idx+1) * self.batch_size]\n        batch_y = [self.labels[0][idx * self.batch_size : (idx+1) * self.batch_size],self.labels[1][idx * self.batch_size : (idx+1) * self.batch_size]]\n       \n    \n        return np.array(batch_x),(batch_y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def load_images(path1,path2, size=(256,512)):\n    src_list,tar_list = list(), list()\n    count1=0\n    count2=0\n    for filename in listdir(path1):\n        if(count1==150):\n            break\n        pixels1 = load_img(path1 + filename, target_size=size)\n        pixels1 = img_to_array(pixels1)\n        src_list.append(pixels1)\n        count1+=1\n\n    for filename in listdir(path2):\n        if(count2==150):\n            break\n        pixels2 = load_img(path2 + filename, target_size=size)\n        pixels2 = img_to_array(pixels2)\n        tar_list.append(pixels2)\n        count2+=1\n    return [asarray(src_list), asarray(tar_list)]\n\n\npath1 ='/kaggle/input/everybody-dance-now1/subject4/train/train_label/'\npath2='/kaggle/input/everybody-dance-now1/subject4/train/train_img/'\n[src_images, tar_images] = load_images(path1,path2)\nprint('Loaded: ', src_images.shape, tar_images.shape)\nfilename = 'dancex_256.npz'\nsavez_compressed(filename, a=src_images, b=tar_images)\nprint('Saved dataset: ', filename)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def load_real_samples(filename):\n    data = load(filename)\n    X1=data['a']\n    X2=data['b']\n    X1 = (X1-127.5)/127.5\n    X2 = (X2-127.5)/127.5\n    return [X1, X2]\nfrom numpy import load\ndataset = load_real_samples('dancex_256.npz')\nprint('Loaded', dataset[0].shape, dataset[1].shape)\nimage_shape = dataset[0].shape[1:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from numpy import load\nfrom numpy import zeros\nfrom numpy import ones\nfrom numpy.random import randint\nfrom keras.optimizers import Adam\nfrom keras.initializers import RandomNormal\nfrom keras.models import Model\nfrom keras.models import Input\nfrom keras.layers import Conv2D\nfrom keras.layers import Conv2DTranspose\nfrom keras.layers import LeakyReLU\nfrom keras.layers import Activation\nfrom keras.layers import Concatenate\nfrom keras.layers import Dropout\nfrom keras.layers import BatchNormalization\nfrom keras.layers import LeakyReLU\nfrom matplotlib import pyplot\nimport cv2\n\n\ndef define_discriminator(image_shape):\n    init = RandomNormal(stddev=0.02)\n    in_src_image = Input(shape=image_shape)\n    in_target_image = Input(shape=image_shape)\n    merged = Concatenate()([in_src_image, in_target_image])\n    d = Conv2D(64, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(merged)\n    d = LeakyReLU(alpha=0.2)(d)\n    d = Conv2D(128, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d)\n    d = BatchNormalization()(d)\n    d = LeakyReLU(alpha=0.2)(d)\n    d = Conv2D(256, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d)\n    d = BatchNormalization()(d)\n    d = LeakyReLU(alpha=0.2)(d)\n    d = Conv2D(512, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d)\n    d = BatchNormalization()(d)\n    d = LeakyReLU(alpha=0.2)(d)\n    d = Conv2D(512, (4,4), padding='same', kernel_initializer=init)(d)\n    d = BatchNormalization()(d)\n    d = LeakyReLU(alpha=0.2)(d)\n    d = Conv2D(1, (4,4), padding='same', kernel_initializer=init)(d)\n    patch_out = Activation('sigmoid')(d)\n    model = Model([in_src_image, in_target_image], patch_out)\n    opt = Adam(lr=0.0002, beta_1=0.5)\n    model.compile(loss='binary_crossentropy', optimizer=opt, loss_weights=[0.5])\n    return model\n\ndef define_encoder_block(layer_in, n_filters, batchnorm=True):\n    init = RandomNormal(stddev=0.02)\n    g = Conv2D(n_filters, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(layer_in)\n    if batchnorm:\n        g = BatchNormalization()(g, training=True)\n    g = LeakyReLU(alpha=0.2)(g)\n    return g\n\ndef decoder_block(layer_in, skip_in, n_filters, dropout=True):\n    init = RandomNormal(stddev=0.02)\n    g = Conv2DTranspose(n_filters, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(layer_in)\n    g = BatchNormalization()(g, training=True)\n    if dropout:\n        g = Dropout(0.5)(g, training=True)\n    g = Concatenate()([g, skip_in])\n    g = Activation('relu')(g)\n    return g\n\ndef define_generator(image_shape=(256,512,3)):\n    init = RandomNormal(stddev=0.02)\n    in_image = Input(shape=image_shape)\n    e1 = define_encoder_block(in_image, 64, batchnorm=False)\n    e2 = define_encoder_block(e1, 128)\n    e3 = define_encoder_block(e2, 256)\n    e4 = define_encoder_block(e3, 512)\n    e5 = define_encoder_block(e4, 512)\n    e6 = define_encoder_block(e5, 512)\n    e7 = define_encoder_block(e6, 512)\n    b = Conv2D(512, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(e7)\n    b = Activation('relu')(b)\n    d1 = decoder_block(b, e7, 512)\n    d2 = decoder_block(d1, e6, 512)\n    d3 = decoder_block(d2, e5, 512)\n    d4 = decoder_block(d3, e4, 512, dropout=False)\n    d5 = decoder_block(d4, e3, 256, dropout=False)\n    d6 = decoder_block(d5, e2, 128, dropout=False)\n    d7 = decoder_block(d6, e1, 64, dropout=False)\n    g = Conv2DTranspose(3, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d7)\n    out_image = Activation('tanh')(g)\n    model = Model(in_image, out_image)\n    return model\n\ndef define_gan(g_model, d_model, image_shape):\n    d_model.trainable = False\n    in_src = Input(shape=image_shape)\n    gen_out = g_model(in_src)\n    dis_out = d_model([in_src, gen_out])\n    model = Model(in_src, [dis_out, gen_out])\n    opt = Adam(lr=0.0002, beta_1=0.5)\n    model.compile(loss=['binary_crossentropy', 'mae'], optimizer=opt, loss_weights=[1,100])\n    return model\n\ndef load_real_samples(filename):\n    data = load(filename)\n    X1, X2 = data['arr_0'], data['arr_1']\n    X1 = (X1 - 127.5) / 127.5\n    X2 = (X2 - 127.5) / 127.5\n    return [X1, X2]\n\ndef generate_real_samples(dataset, n_samples, patch_shape):\n    trainA, trainB = dataset\n    ix = randint(0, trainA.shape[0], n_samples)\n    X1, X2 = trainA[ix], trainB[ix]\n    y = ones((n_samples, patch_shape, patch_shape*2, 1))\n    return [X1, X2], y\n\ndef generate_fake_samples(g_model, samples, patch_shape):\n    X = g_model.predict(samples)\n    y = zeros((len(X), patch_shape, patch_shape*2, 1))\n    return X, y\n\ndef summarize_performance(step, g_model, dataset, n_samples=1):\n    [X_realA, X_realB], _ = generate_real_samples(dataset, n_samples, 1)\n    X_fakeB, _ = generate_fake_samples(g_model, X_realA, 1)\n    X_realA = (X_realA + 1) / 2.0\n    X_realB = (X_realB + 1) / 2.0\n    X_fakeB = (X_fakeB + 1) / 2.0\n \n    print(\"Pose stick figure\")\n    for i in range(n_samples):\n        pyplot.figure(figsize=(6.5,6.5))\n#         pyplot.subplot(3, n_samples, 1 + i)\n        pyplot.axis('off')\n        v=pyplot.imshow(X_realA[i])\n        \n        pyplot.show()\n   \n    print(\"Generated fake image\")\n    for i in range(n_samples):\n        pyplot.figure(figsize=(6.5,6.5))\n        #pyplot.subplot(1, 2, 1)\n        pyplot.axis('off')\n        pyplot.imshow(X_fakeB[i])\n       # print(X_fakeB[i].shape)\n        pyplot.show()\n\n    print(\"Real Image\")\n    for i in range(n_samples):\n        pyplot.figure(figsize=(6.5,6.5))\n        #pyplot.subplot(1,2,2)\n        pyplot.axis('off')\n        pyplot.imshow(X_realB[i])\n        pyplot.show()\n    #filename1 = 'plot_%06d.png' % (step+1)\n    #pyplot.savefig(filename1)\n    #pyplot.close()\n    #filename2 = 'model_%06d.h5' % (step+1)\n    #g_model.save(filename2)\n    #print('Saved: %s and %s' % (filename1, filename2))\n\n\ndef train(d_model, g_model, gan_model, dataset, n_batch=150):\n    n_patch = d_model.output_shape[1]\n    trainA, trainB = dataset\n    \n    n_steps=20\n    \n    for i in range(n_steps): \n        [X_realA, X_realB], y_real = generate_real_samples(dataset, n_batch, n_patch)\n        X_fakeB, y_fake = generate_fake_samples(g_model, X_realA, n_patch)\n        X_realA_train=X_realA[:120]\n        X_realA_val=X_realA[120:]\n        X_realB_train=X_realB[:120]\n        X_realB_val=X_realB[120:]\n        X_fakeB_train=X_fakeB[:120]\n        X_fakeB_val=X_fakeB[120:]\n        y_real_train=y_real[:120]\n        y_real_val=y_real[120:]\n        y_fake_train=y_fake[:120]\n        y_fake_val=y_fake[120:]\n        d_model.trainable=True\n        batch_size=15\n        my_dis_gen_real=My_Custom_Generator(X_realA_train,X_realB_train,y_real_train,batch_size)\n        my_val_gen_real=My_Custom_Generator(X_realA_val,X_realB_val,y_real_val,batch_size)\n        d_model.fit_generator(generator=my_dis_gen_real,\n                   steps_per_epoch = int(150// batch_size),\n                   epochs = 100,verbose = 0,validation_data = my_val_gen_real)\n        # d_loss1 = d_model.train_on_batch([X_realA, X_realB], y_real)\n        my_dis_gen_fake=My_Custom_Generator(X_realA_train,X_fakeB_train,y_fake_train,batch_size)\n        my_val_gen_fake=My_Custom_Generator(X_realA_val,X_fakeB_val,y_fake_val,batch_size)\n        d_model.fit_generator(generator=my_dis_gen_fake,\n                   steps_per_epoch = int(150// batch_size),\n                   epochs = 100, verbose = 0,validation_data = my_val_gen_fake)\n        # d_loss2 = d_model.train_on_batch([X_realA, X_fakeB], y_fake)\n        d_model.trainable=False\n        #g_loss, _, _ = gan_model.train_on_batch(X_realA, [y_real, X_realB])\n        my_gan_gen=My_Custom_Generator_gan(X_realA_train,y_real_train,X_realB_train,batch_size)\n        my_val_gen=My_Custom_Generator_gan(X_realA_val,y_real_val,X_realB_val,batch_size)\n        gan_model.fit_generator(generator=my_gan_gen,\n                   steps_per_epoch = int(150// batch_size),\n                   epochs = 100, verbose = 0, validation_data = my_val_gen)\n        print('Epoch %d/%d completed' % (i+1,n_steps))\n        if (i) % (2) == 0:\n            summarize_performance(i, g_model, dataset)\n        g_model_json = g_model.to_json()\n        with open(\"g_model.json\", \"w\") as json_file:\n            json_file.write(g_model_json)\n        g_model.save_weights(\"modelgen.h5\")\n        print(\"Saved model to disk\")\n\n\nd_model = define_discriminator(image_shape)\ng_model = define_generator(image_shape)\ngan_model = define_gan(g_model, d_model, image_shape)\ntrain(d_model, g_model, gan_model, dataset)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport cv2\nfrom os import listdir\nfrom numpy import asarray\nfrom numpy import vstack\nfrom keras.preprocessing.image import img_to_array\nfrom keras.preprocessing.image import load_img\nfrom numpy import savez_compressed\nimport keras\nimport numpy as np","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import model_from_json\njson_file = open('/kaggle/input/final00000/g_model.json', 'r')\nloadedx_model_json = json_file.read()\njson_file.close()\nloadedx_model = model_from_json(loadedx_model_json)\nloadedx_model.load_weights(\"/kaggle/input/final00000/modelgen.h5\")\nprint(\"Loaded model from disk\")\n ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure()\nplt.imshow(src_images[6].reshape(256,512,3)/255)\nplt.show()\nplt.figure()\nplt.imshow(tar_images[6].reshape(256,512,3)/255)\nplt.show()\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#x=x.reshape(1,256,512,3)\nx=(x-127.5)/127.5\nx=loadedx_model.predict(src_images)\nx = (x + 1) / 2.0\nprint(x.shape)\nplt.imshow(x.reshape(256,512,3))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nimport numpy as np\n#from PIL import Image\ncount1=0\nsize=(256,512)\n#path1=\"/kaggle/input/everybody-dance-nowsubject-1/subject1/train/train_label/\"\n#pixels1 = load_img(path1 , target_size=size)\n#x = img_to_array(pixels1)\nif not os.path.isdir(\"output_images_subject2\"):\n    os.mkdir(\"output_images_subject2\")\npath1=\"/kaggle/input/eveerybody-dance-nowsubject-2/subject2/train/train_label/\"\ni=0\nfor filename in listdir(path1):\n        if(count1==1000):\n            break\n        count1=count1+1\n        pixels1 = load_img(path1 + filename, target_size=size)\n        x = img_to_array(pixels1)\n        x=(x-127.5)/127.5\n        x=x.reshape(1,256,512,3)\n        pixels1=loadedx_model.predict(x)\n        pixels1 = (pixels1 + 1) / 2.0\n        print(pixels1.shape)\n        pixels1=pixels1.reshape(256,512,3)\n        plt.figure()\n        plt.axis(\"off\")\n        plt.imshow(pixels1)\n        plt.savefig(\"output_images_subject2/final_{0}.png\".format(i+1))\n        plt.show()\n#         plt.savefig(\"output_images/{:06d}.format(i+1).png\",pixels1)\n        #plt.imshow(\"output_images\")\n        i=i+1\n       \n        \n        \n        \n#x=plt.imread(\"/kaggle/input/eveerybody-dance-nowsubject-2/subject2/train/train_label/frame003000.png\")\n#print(x.shape)\n#print(type(x))\n\n\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import cv2\nimport numpy as np\nimport os\nfrom os.path import isfile, join\npathIn= 'output_images_subject2/'\npathOut = 'videotarget_subject2.avi'\nfps = 5\nframe_array = []\nfiles = [f for f in os.listdir(pathIn) if isfile(join(pathIn, f))]\n#files.sort(key = lambda x: x[5:-4])\nfiles.sort()\nframe_array = []\n#files = [f for f in os.listdir(pathIn) if isfile(join(pathIn, f))]\n#files.sort(key = lambda x: x[5:-4])\nfor i in range(1000):\n    filename=pathIn + files[i]\n    img = cv2.imread(filename)\n    height, width, layers = img.shape\n    size = (width,height)\n    frame_array.append(img)\nout = cv2.VideoWriter(pathOut,cv2.VideoWriter_fourcc(*'DIVX'), fps, size)\nfor i in range(len(frame_array)):\n    out.write(frame_array[i])\nout.release()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nif not os.path.isdir(\"epoch_images\"):\n    os.mkdir(\"epoch_images\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"v=x[3].reshape(256,512,3)\nplt.imshow(v)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nx=plt.imread(\"/kaggle/input/eveerybody-dance-nowsubject-1/subject1/train/train_label/frame000001.png\")\nx.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"g_model_json = g_model.to_json()\nwith open(\"g_modelx.json\", \"w\") as json_file:\n    json_file.write(g_model_json)\ng_model.save_weights(\"modelgenx.h5\")\nprint(\"Saved model to disk\")\n \n\n \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import cv2\nimport matplotlib.pyplot as plt\nimport os\nfrom os import listdir\nv=plt.imread('/kaggle/input/everybody-dance-now1/subject4/train/train_img/frame020001.png')\nif not os.path.isdir(\"output_images\"):\n    os.mkdir(\"output_images\")\nx=plt.imshow(v)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cv2.imwrite(\"output_images/1.png\",v)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#im_rgb = cv2.cvtColor(im_cv, cv2.COLOR_BGR2RGB)\nx=plt.imread(\"output_images/1.png\")\n#im = cv2.cvtColor(x, cv2.COLOR_BGR2RGB)\nplt.imshow(x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}